{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2c4268c",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 自定义层\n",
    "\n",
    "深度学习成功背后的一个因素是神经网络的灵活性：\n",
    "我们可以用创造性的方式组合不同的层，从而设计出适用于各种任务的架构。\n",
    "例如，研究人员发明了专门用于处理图像、文本、序列数据和执行动态规划的层。\n",
    "有时我们会遇到或要自己发明一个现在在深度学习框架中还不存在的层。\n",
    "在这些情况下，必须构建自定义层。本节将展示如何构建自定义层。\n",
    "\n",
    "## 不带参数的层\n",
    "\n",
    "首先，我们(**构造一个没有任何参数的自定义层**)。\n",
    "回忆一下在 :numref:`sec_model_construction`对块的介绍，\n",
    "这应该看起来很眼熟。\n",
    "下面的`CenteredLayer`类要从其输入中减去均值。\n",
    "要构建它，我们只需继承基础层类并实现前向传播功能。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcccedea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:00:42.700516Z",
     "iopub.status.busy": "2022-12-07T17:00:42.700056Z",
     "iopub.status.idle": "2022-12-07T17:00:43.838393Z",
     "shell.execute_reply": "2022-12-07T17:00:43.837505Z"
    },
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X - X.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bad6f33",
   "metadata": {
    "origin_pos": 5
   },
   "source": [
    "让我们向该层提供一些数据，验证它是否能按预期工作。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b4d1d06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:00:43.842407Z",
     "iopub.status.busy": "2022-12-07T17:00:43.841864Z",
     "iopub.status.idle": "2022-12-07T17:00:43.856009Z",
     "shell.execute_reply": "2022-12-07T17:00:43.855164Z"
    },
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = CenteredLayer()\n",
    "layer(torch.FloatTensor([1, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5c194e",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "现在，我们可以[**将层作为组件合并到更复杂的模型中**]。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "940a1768",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:00:43.859555Z",
     "iopub.status.busy": "2022-12-07T17:00:43.859007Z",
     "iopub.status.idle": "2022-12-07T17:00:43.864905Z",
     "shell.execute_reply": "2022-12-07T17:00:43.864115Z"
    },
    "origin_pos": 12,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(8, 128), CenteredLayer())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3ed550",
   "metadata": {
    "origin_pos": 14
   },
   "source": [
    "作为额外的健全性检查，我们可以在向该网络发送随机数据后，检查均值是否为0。\n",
    "由于我们处理的是浮点数，因为存储精度的原因，我们仍然可能会看到一个非常小的非零数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "235e88c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:00:43.868175Z",
     "iopub.status.busy": "2022-12-07T17:00:43.867649Z",
     "iopub.status.idle": "2022-12-07T17:00:43.873777Z",
     "shell.execute_reply": "2022-12-07T17:00:43.873018Z"
    },
    "origin_pos": 16,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1315,  0.2825, -0.0141,  0.1366, -0.3708,  0.4238, -0.0427, -0.5763,\n",
      "          0.1321,  0.0577,  0.6263, -0.5594, -0.6086, -0.3592,  0.9616,  0.6024,\n",
      "          0.4735, -0.2972,  0.9424, -0.1184,  0.0457, -0.3545,  0.3688, -1.1623,\n",
      "         -0.7682,  0.3067,  0.6842,  0.6159, -0.1157, -0.0697,  0.3461, -0.0831,\n",
      "         -0.1799, -0.2460, -0.4183,  0.6505, -0.3914, -0.4517, -0.3404, -0.1135,\n",
      "          0.5236,  0.2700,  0.4880, -0.1711,  0.6260, -0.6326, -0.1620,  0.7112,\n",
      "         -1.0369, -0.7556,  0.0082,  0.3500,  0.2307,  0.1353,  0.9889, -0.5606,\n",
      "         -0.3582, -0.1032, -0.4990,  1.0232,  0.4340,  0.0137,  0.8552,  0.9319,\n",
      "          0.0800,  0.4218,  0.0543, -0.1338, -0.5242, -1.0258, -0.5044, -0.7414,\n",
      "         -0.6582,  0.4325, -0.4005, -0.4117, -0.4024,  0.1501, -0.2236,  0.1007,\n",
      "          0.6182, -0.0742, -0.0316,  0.0490,  0.0956,  0.3021,  0.1952, -0.7597,\n",
      "          0.3634,  0.8629,  0.0963, -0.0934, -0.3613,  0.6510, -0.6861,  0.2040,\n",
      "         -0.3028, -0.3938,  0.2955,  0.6302, -0.4328, -0.5132, -0.4716,  0.1407,\n",
      "          0.0677, -0.0088,  0.3982, -0.2982, -1.0774,  0.5330,  0.5911, -0.4904,\n",
      "          0.2078, -1.0015,  0.4743,  0.9535,  0.0743, -0.3833, -0.3712,  0.2176,\n",
      "         -0.2919,  0.5709,  0.2315, -0.4675, -0.2738,  0.5127, -0.0731,  0.0049],\n",
      "        [-0.0734,  0.2989,  0.1779,  0.0857, -0.1878,  0.3635, -0.0470, -0.1462,\n",
      "         -0.4478, -0.1544,  0.5423, -0.6092, -0.3221,  0.0233,  0.6848,  0.3028,\n",
      "          0.0794, -0.1520,  0.6470, -0.4048,  0.4713, -0.2641,  0.2734, -0.7504,\n",
      "         -0.6279,  0.0972,  0.5465,  0.5225, -0.1809, -0.3710,  0.3133, -0.0550,\n",
      "         -0.1499,  0.2420, -0.6180,  0.2667, -0.4006, -0.1169, -0.2645, -0.2669,\n",
      "          0.5200,  0.4184,  0.3825,  0.0964,  0.6694, -0.3229,  0.1290,  0.5753,\n",
      "         -0.7767, -0.6271, -0.3537, -0.0416,  0.1898,  0.1213,  0.7361, -0.3692,\n",
      "         -0.0343, -0.1057, -0.0943,  0.8233,  0.6083, -0.2341,  0.5469,  0.5555,\n",
      "          0.1229,  0.0488, -0.1907, -0.0528, -0.2913, -0.6609, -0.3725, -0.5602,\n",
      "         -0.3388, -0.0887, -0.0804, -0.1785, -0.2648,  0.3897, -0.2268,  0.1758,\n",
      "          0.1920, -0.0315, -0.4539,  0.1119,  0.3924,  0.3497,  0.3465, -0.2550,\n",
      "          0.2369,  0.3400, -0.1751, -0.2341, -0.0681,  0.6568, -0.1295,  0.4090,\n",
      "         -0.0341, -0.3813,  0.0403,  0.3432, -0.2019, -0.0607, -0.3079,  0.0792,\n",
      "         -0.1085, -0.0345,  0.1146,  0.0514, -0.7278,  0.1782,  0.6915, -0.6030,\n",
      "         -0.0886, -0.8444,  0.1088,  0.4252,  0.2518, -0.2351, -0.2348,  0.1431,\n",
      "         -0.3414,  0.4413,  0.5051, -0.3110, -0.3514,  0.3566,  0.1824, -0.0507],\n",
      "        [-0.0587,  0.3979,  0.1648,  0.0851, -0.1580,  0.6956, -0.0220, -0.6541,\n",
      "          0.0207, -0.1529,  0.5259, -0.5802, -0.6239, -0.1318,  1.1303,  0.3673,\n",
      "          0.6349, -0.0593,  0.8903, -0.0349, -0.1013, -0.3838,  0.5846, -1.0041,\n",
      "         -0.5570,  0.0980,  0.5694,  0.5823, -0.0657,  0.0324,  0.2868, -0.3537,\n",
      "          0.1606, -0.3983, -0.4805,  0.6001, -0.2270, -0.2076, -0.2343,  0.0466,\n",
      "          0.2811,  0.0053,  0.4736, -0.2658,  0.3933, -0.6128, -0.1748,  0.4166,\n",
      "         -0.8531, -0.4194, -0.1435,  0.3425,  0.1266, -0.2297,  0.7628, -0.3655,\n",
      "         -0.3457, -0.2910, -0.3448,  0.8877,  0.6212,  0.0926,  0.8100,  0.8591,\n",
      "          0.0344,  0.6486, -0.1822, -0.1437, -0.3312, -0.9897, -0.6105, -0.7352,\n",
      "         -0.3984,  0.3639, -0.2607, -0.4579, -0.5111,  0.2541, -0.2215,  0.1539,\n",
      "          0.5274,  0.1090, -0.1197,  0.2332,  0.1649,  0.3584,  0.0634, -0.4636,\n",
      "          0.2705,  0.8511,  0.0723,  0.1523, -0.5151,  0.5590, -0.3395,  0.1335,\n",
      "         -0.2165, -0.4222,  0.0116,  0.7420, -0.6989, -0.3944, -0.2178, -0.0391,\n",
      "          0.1279,  0.0467,  0.1749, -0.3723, -0.8885,  0.2700,  0.5081, -0.3197,\n",
      "          0.2066, -0.6539,  0.4743,  0.6848, -0.1400, -0.3366, -0.0993,  0.1264,\n",
      "         -0.5043,  0.3660,  0.0249, -0.4465, -0.1481,  0.3553, -0.0273,  0.0910],\n",
      "        [ 0.0604,  0.0570,  0.0169,  0.0783, -0.3570,  0.3003, -0.1489, -0.4844,\n",
      "          0.0266,  0.1387,  0.5235, -0.4401, -0.3047, -0.1157,  0.6435,  0.5993,\n",
      "          0.2540, -0.2010,  0.7437, -0.2328,  0.2283, -0.2870,  0.1328, -0.8667,\n",
      "         -0.6036,  0.3606,  0.6391,  0.2805, -0.0917, -0.2259,  0.1286,  0.0401,\n",
      "         -0.2683, -0.0412, -0.5319,  0.5083, -0.4415, -0.3405, -0.4133,  0.0405,\n",
      "          0.5976,  0.4578,  0.3393, -0.0724,  0.5608, -0.4463, -0.0517,  0.5295,\n",
      "         -0.9998, -0.6143,  0.0110,  0.0759,  0.0809,  0.1868,  0.6807, -0.4112,\n",
      "         -0.2516, -0.0856, -0.4075,  0.7952,  0.3594, -0.0713,  0.5141,  0.6851,\n",
      "          0.0538,  0.0129,  0.0413, -0.1310, -0.4434, -0.7707, -0.3524, -0.4745,\n",
      "         -0.5132,  0.0807, -0.2387, -0.2821, -0.1806,  0.1855, -0.1957,  0.1398,\n",
      "          0.4523, -0.2876, -0.0616,  0.0961,  0.1043,  0.3603,  0.1384, -0.4900,\n",
      "          0.3486,  0.5067, -0.1042, -0.0934, -0.2929,  0.7188, -0.4703,  0.2475,\n",
      "          0.0139, -0.0923,  0.2166,  0.4765, -0.2181, -0.5466, -0.4547,  0.1313,\n",
      "         -0.0185, -0.0375,  0.0809, -0.1685, -0.9629,  0.3632,  0.5988, -0.5058,\n",
      "         -0.0274, -0.8707,  0.3411,  0.7056, -0.0226, -0.3035, -0.2646,  0.1386,\n",
      "         -0.2095,  0.4250,  0.2066, -0.2561, -0.2913,  0.5265, -0.0990,  0.0407]],\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-5.5879e-09, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = net(torch.rand(4, 8))\n",
    "print(Y)\n",
    "Y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406e792f",
   "metadata": {
    "origin_pos": 19
   },
   "source": [
    "## [**带参数的层**]\n",
    "\n",
    "以上我们知道了如何定义简单的层，下面我们继续定义具有参数的层，\n",
    "这些参数可以通过训练进行调整。\n",
    "我们可以使用内置函数来创建参数，这些函数提供一些基本的管理功能。\n",
    "比如管理访问、初始化、共享、保存和加载模型参数。\n",
    "这样做的好处之一是：我们不需要为每个自定义层编写自定义的序列化程序。\n",
    "\n",
    "现在，让我们实现自定义版本的全连接层。\n",
    "回想一下，该层需要两个参数，一个用于表示权重，另一个用于表示偏置项。\n",
    "在此实现中，我们使用修正线性单元作为激活函数。\n",
    "该层需要输入参数：`in_units`和`units`，分别表示输入数和输出数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7daf5257",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:00:43.877216Z",
     "iopub.status.busy": "2022-12-07T17:00:43.876666Z",
     "iopub.status.idle": "2022-12-07T17:00:43.881991Z",
     "shell.execute_reply": "2022-12-07T17:00:43.881201Z"
    },
    "origin_pos": 21,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_units, units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
    "        self.bias = nn.Parameter(torch.randn(units,))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
    "        return F.relu(linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefaab88",
   "metadata": {
    "origin_pos": 25,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "接下来，我们实例化`MyLinear`类并访问其模型参数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f698e334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:00:43.885384Z",
     "iopub.status.busy": "2022-12-07T17:00:43.884832Z",
     "iopub.status.idle": "2022-12-07T17:00:43.891052Z",
     "shell.execute_reply": "2022-12-07T17:00:43.890262Z"
    },
    "origin_pos": 28,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.1050,  0.2539, -0.6508],\n",
       "        [ 1.0387, -0.3283,  1.7847],\n",
       "        [-0.7417, -0.5461,  1.2678],\n",
       "        [ 1.5695,  1.0861, -2.3013],\n",
       "        [-1.7376,  0.4236, -0.8101]], requires_grad=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = MyLinear(5, 3)\n",
    "linear.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3e70bb",
   "metadata": {
    "origin_pos": 30
   },
   "source": [
    "我们可以[**使用自定义层直接执行前向传播计算**]。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73bdadeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:00:43.894343Z",
     "iopub.status.busy": "2022-12-07T17:00:43.893790Z",
     "iopub.status.idle": "2022-12-07T17:00:43.899843Z",
     "shell.execute_reply": "2022-12-07T17:00:43.899055Z"
    },
    "origin_pos": 32,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0868, 0.0341],\n",
       "        [0.0000, 0.0000, 0.7865]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(torch.rand(2, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e9b68f",
   "metadata": {
    "origin_pos": 35
   },
   "source": [
    "我们还可以(**使用自定义层构建模型**)，就像使用内置的全连接层一样使用自定义层。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "062d9c7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:00:43.903259Z",
     "iopub.status.busy": "2022-12-07T17:00:43.902701Z",
     "iopub.status.idle": "2022-12-07T17:00:43.909376Z",
     "shell.execute_reply": "2022-12-07T17:00:43.908630Z"
    },
    "origin_pos": 37,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n",
    "net(torch.rand(2, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b798a9f4",
   "metadata": {
    "origin_pos": 40
   },
   "source": [
    "## 小结\n",
    "\n",
    "* 我们可以通过基本层类设计自定义层。这允许我们定义灵活的新层，其行为与深度学习框架中的任何现有层不同。\n",
    "* 在自定义层定义完成后，我们就可以在任意环境和网络架构中调用该自定义层。\n",
    "* 层可以有局部参数，这些参数可以通过内置函数创建。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 设计一个接受输入并计算张量降维的层，它返回$y_k = \\sum_{i, j} W_{ijk} x_i x_j$。\n",
    "1. 设计一个返回输入数据的傅立叶系数前半部分的层。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da253c7",
   "metadata": {
    "origin_pos": 42,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/1835)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
